---
title: "Week 7"
---

<div style="text-align: justify">

## Summary of Lecture 7

```{r echo=FALSE,cache=FALSE, fig.align='center', fig.cap="The feature relations map learning (FRML) chart for hyperspectral image classification. Source: mdpi.com/2072-4292/12/18/2956"}
knitr::include_graphics('https://www.mdpi.com/remotesensing/remotesensing-12-02956/article_deploy/html/images/remotesensing-12-02956-g001.png')
```

Due to the synoptic view nature in remote sensing images, the remote sensing images produces are in map-like format, making it a viable source of gathering effective land cover information. However, just the raw image and identification with the naked eye is not reliable and accurate. Therefore, basic image classification is important to categorize all pixels in a digital image into one of several classes. Image classification is regarded as one of the most essential part in digital image analysis as it allows allocation of semantic labels to capture image. It is useful for research, and policy making purposes as it provides better understanding and details to the content within the image. The image above is a type of image processing using a technique of **Feature Relations Map Learning** for hyperspectral image, it automatically enhance the separability of different objects in an image [@dou2020]. While using a segmented feature relations map (SFRM), it reflects the relations between spectral features through a normalized difference index (NDI), and it can then learn new features from SFRM using a CNN-based feature extractor [@dou2020]. Conventionally, there are three types of image classification, including

1.  ***Manual Classification***

2.  ***Pixel-based classification***

    1.  Supervised image classification

    2.  Unsupervised image classification

3.  ***Feature or object-based image classification***

### ***Pixel-based Classification***

In pixel-based classification, there are two types of image classifications,including **Unsupervised** and **Supervised** classification, where unsupervised classification is calculated by the software supervised is mainly a human-guided classification. The supervised image classification creates outcomes that are based on the software analysis without giving it sample classes. On the other hand, unsupervised classification creates outcome that is aided by providing sample pixels in an image that are representative of specific classes and then direct the image processing software to use these training sites as references for the classification of all other pixels in the image. The figures below shows the two types of image classification technique used on the same image, producing approximately similar results, yet the details are quite different.

```{r echo=FALSE, cache=FALSE, out.width="100%", fig.align='center', fig.cap="Supervised and unsupervised classification on an image. Source: https://beekangsi.com/the-pros-and-cons-supervised-and-unsupervised-image-classification/"}
knitr::include_graphics('https://i0.wp.com/beekangsi.com/wp-content/uploads/2022/04/Supervised-and-unsupervised-classification-of-SPOT-5-image-of-the-study-area-1.jpg?fit=738%2C613&ssl=1&w=640')
```

Referencing to [@bekan2022]'s GIS blog about the pros and cons of supervised and unsupervised image classification, both classification techniques have their advantages and disadvantages, it is hard to determine which technique is better as it depends on the focus with the results. The

+---------------------------------+--------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------+
|                                 | Advantage                                                                                        | Disadvantage                                                                    |
+=================================+==================================================================================================+=================================================================================+
| **Unsupervised Classification** | 1.  The operator can spot mistakes and often corrects them.                                      | 1.  gathering training for different class is very difficult and time consuming |
|                                 |                                                                                                  |                                                                                 |
|                                 | 2.  The analyst does not have to worry about matching categories on the final map to field data. | 2.  the unrepresented place in training data is difficult to recognize          |
|                                 |                                                                                                  |                                                                                 |
|                                 | 3.  The process is completely within the control of the analyzer.                                | 3.  needs very clear training process                                           |
|                                 |                                                                                                  |                                                                                 |
|                                 | 4.  Specific sections of known identity are linked to processing.                                | 4.  and also requires labelled data set                                         |
|                                 |                                                                                                  |                                                                                 |
|                                 | 5.  the class s defined by the Analyst                                                           |                                                                                 |
|                                 |                                                                                                  |                                                                                 |
|                                 | \                                                                                                |                                                                                 |
+---------------------------------+--------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------+
| **Supervised Classification**   | 1.  It is not necessary to label the training data set.                                          | 1.  Along the classification process, there is no concept of output.            |
|                                 |                                                                                                  |                                                                                 |
|                                 | 2.  it is time saving process                                                                    | 2.  It is not possible to estimate or map the outcome of a new sample.          |
|                                 |                                                                                                  |                                                                                 |
|                                 | 3.  fast classification                                                                          | 3.  In the presence of outliers, the outcome varies greatly.                    |
+---------------------------------+--------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------+

### **Object Based Image Analysis (OBIA)**

In the lecture, another type of image classification is taught, the **Object based image analysis (OBIA)**. It involves pixels first being grouped into objects based on either spectral similarity or an external variable such as ownership, land use, shape and geological unit. **Superpixels** in OBIA are segmentating an image into regions by considering similarity(homogenity) or difference(heterogeneity) measures defined using perceptual features. To achieve that, Simple Linear Iterative Clustering (SLIC) algorithm is commonly used to generate Superpixels. SLIC uses euclidean distance to work out spatial distance between points to centre of pixels and is an adapted k means clustering. Thereby, it does not consider connectivity and do not compare each pixels with all pixels in the scene. Different from SLIC, another version of SLIC that is parameter-free has been proposed, called SLICO. It generates regular shaped Superpixels across the scene, regardless of textured or non-textured regions in the image.

```{r echo=FALSE, cache=FALSE, out.width="100%", fig.align='center', fig.cap="SLIC and SLICO Superpixel Generation. Source: https://www.mdpi.com/2072-4292/9/3/243"}
knitr::include_graphics('https://www.mdpi.com/remotesensing/remotesensing-09-00243/article_deploy/html/images/remotesensing-09-00243-g004-550.jpg')
```

### Sub Pixel Analysis

Sub pixel classification (SPC) extracts meaningful information on land-cover classes from the mixed pixels. The figure below shows what a mixed pixel looks like. The proportion and abundance of each classes in the mixed pixel can be accounted for. In general, a few endmembers that are specturally pure are generated will work out fractions per pixel and establish a spectral library.

```{r echo=FALSE, cache=FALSE, out.width="100%", fig.align='center', fig.cap="Sparse modeling at sub-pixel level using the pre-learned dictionary. Source: https://www.mdpi.com/2072-4292/13/2/190"}
knitr::include_graphics('https://www.mdpi.com/remotesensing/remotesensing-13-00190/article_deploy/html/images/remotesensing-13-00190-g004-550.jpg')

```

According to [@powell2007], for multiple endmember, Spectral mixture analysis (SMA) is done based on the assumptionthat the reflectance P' measured at pixel i can be modeled as the linear sum of N endmembers, or spectrally 'pure' materials, weighted by the fraction cover fki of each endmember within the field of view of pixel i. Below shows the calculation of the sum of end member reflectance franction contribution to best-fit mixed spectrum where eiλ is a residual term indicating the disagreement between the measured and modeled spectra.:

$$
p_i\lambda=\sum_{k=1}^{n} (p_{ki\lambda} * f_ki) + ei_\lambda
$$

By the end, there will be the percentage/fraction of components for each pixels, for example, fraction of vegetation, soil, urban areas.

## Application

To actually understand how classification works, in this week's practical, I have chosen Shiga, a prefecture of Japan that is located in the Kansai Region of Honshu.

```{r echo=FALSE, cache=FALSE, out.width="100%", fig.align='center', fig.cap="Shiga"}
knitr::include_graphics('figures/week7_japanshiga.png')

```

**: A narrative /discussion on how the data / concepts / methods (or related
concepts) have been applied in literature / policy or other studies. It is vital to do some
reading and reference it each week. Here you must comment on the approaches in
literature.**

## Reflection
