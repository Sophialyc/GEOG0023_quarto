[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GEOG0023 – Learning Diary",
    "section": "",
    "text": "Welcome\nMy name is Ling Yi Cheung, Sophia. I was born and raised in Hong Kong, I have recently finished my Bachelor’s degree at the Chinese University of Hong Kong in 2022, majoring in Geography and Resource Management. I would love to share a picture of one of my favourite places in Hong Kong, which is the Victoria Harbour, it separates the Hong Kong Island in the south from the Kowloon Peninsula to the north.\n\n\n\n\n\nHong Kong’s skyline. Source:https://www.telegraph.co.uk/content/dam/Travel/Destinations/Asia/Hong%20Kong/hong-kong-victoria-peak-pano-guide.jpg\n\n\n\n\nWith interest in geospatial science, I have decided to pursue a Master’s degree related to it, hence, I am now studying the MSc Social and Geographic Data Science at UCL. I am very new to programming, and it is always a challenge for me to troubleshoot errors and problems in Rstudio and python when performing different types of spatial analysis, and data manipulation. I hope to improve and enhance my skills on geospatial science in this degree. Besides, I want to learn more about remote sensing, because I have not been taking many courses related to remote sensing in the past. So, I hope I can learn about the principles and important concepts in remote sensing, and utilize the knowledge in the future. For each week, there will be summary and application example, followed by a reflection, please enjoy."
  },
  {
    "objectID": "Week1.html#summary-of-lecture-1",
    "href": "Week1.html#summary-of-lecture-1",
    "title": "1  Week 1",
    "section": "1.1 Summary of Lecture 1",
    "text": "1.1 Summary of Lecture 1\nRemote sensing in short is the detection and monitoring of the earth or a certain area through measurements of the reflected and emitted radiation at a distance. There are various types of remote sensing instruments, and there are 2 types of them, including active sensor and passive sensor.\n\nActive Sensors: Contain own energy source for illumination. They illuminate target objects and actively send pulses and measure the backscatters reflected to them. Synthetic Aperture Radar (SAR) and laser fluorosensor are examples of active sensors.\nPassive Sensors: Do not have any illuminating source. They detect and reflect energy when it is naturally available, and only take place during the time when the sun is illuminating the Earth. Passive infrared sensor (PIR) and radiometers are examples of passive sensors.\n\nThe aforementioned term of “energy” is concisely referring to the energy emitted from the sun, which comes as Electromagnetic radiation (EMR) or Electromagnetic waves (EM waves) to the earth. They are waves of magnetic and electric fields spreading across different wavelength from very short gamma rays, x-ray to infrared waves, and micro waves etc. EM waves travel through vacuum of space at constant speed of light.\n\n\n\n\n\nThe Electromagnetic Spectrum. Source:https://mynasadata.larc.nasa.gov/basic-page/electromagnetic-spectrum-diagram\n\n\n\n\nBefore EMR is received by sensors, several processes and changes are required before hitting the sensors, including energy absorption by the surface, transmission through surface and scattering by particles in the atmosphere.\nIn practical 1, sentinel products were used. It is a product that has been processed through multi-spectral imagery. The spectral imagery is one of the four resolutions used in all remotely sensed data, it contains layer of different bands. I have chosen the Zeeland province of the Netherlands, it is located in the southwestern part consisting islands and peninsulas which are interconnected by the dams and bridges of the Delta Works.\n\n\n\n\n\n\n\n\n\nThis figure shown above is a True Color Image (TCI) that contains B02, B03 and B04 for blue, green and red bands. Yet, the image remain a single raster layer that has a limited value from 0 - 255. In order to enhance the resolution for the sentinel product that has higher much higher brightness level, a raster band could be made manually with the existing separate bands from the Sentinel-2 Level-2A product.\n\n\n\n\n\n\n\n\n\nAs shown in the figure, I have recreated the true color composite using the RGB window, selecting band B04 , B03 and B02 for red, green and blue respectively. The image colour is slightly different from the TCI because I have used the ‘Colour Manipulation’ function to change the distribution of the three bands. The scatter plot on the left shows B04 against B08, which implies the vegetation cover of the area. As the y-axis is the near-infrared reflectance, and x-axis is the red band, high values of y and low values of x in the plot represents dense canopy while low values of both x and y are most likely wet bare soil. From the graph, the image contains little vegetation cover and more soil that is wet and bare."
  },
  {
    "objectID": "Week1.html#application",
    "href": "Week1.html#application",
    "title": "1  Week 1",
    "section": "1.2 Application",
    "text": "1.2 Application\nWhile remote sensors detect, quantify and record the EM energy, the captured satellite images are geo-referenced. One of the most common applications is land cover remote sensing analysis. According to Aplin (2004), different land cover features reflect EM radiation differently, hence, the distinctive radiation provides the representations of land cover variation. As passive sensors require external illumination source, they are dependent to the sun as a source of light and are limited by various conditions. Tempfli et al. (2009) stated that at conditions like during nighttime, when solar radiation is absent and in areas that are mostly covered under clouds, remote sensors are useless. On the contrary, active sensors that have their own source of illumination can operate at any time because they are can emit EM energy and detect the energy returning from the target object or surface.\nSentinel-2A Level 2A products provide Bottom Of Atmosphere (BOA) reflectance images derived from the associated Level-1C products that provide Top-Of-Atmosphere (TOA) reflectance. The Sentinel 2 product has 13 bands of data in 10, 20 and 60 meters pixel size respectively and carries the Multispectral Imager (MSI). B04, B03 and B02 represent Red, Green and Blue respectively, the combination of these 3 bands creates a natural colour imagery that resembles the same way our eyes visualize the real world.\n\n\n\n\n\n\n\n\n\nIn this image, urban features tend to appear in white and grey, while water is dark blue and vegetation is green. This image is very similar to the TCI provided in the data downloaded\nAs vegetation strongly reflects near-infrared radiation and absorbs red light, rather than generating a vegetation index ((B8-B4)/(B8+B4)), a scatter plot of B8 against B4 can also reflect vegetation of the image. From the figure below, the “Tasseled Cap” shape is created. It reveals that vegetation does not contribute big proportion in the image as the zone of low red and high near infrared values are narrow. Instead, many values concentrate at the low red and low infrared regions, showing that water is present and has higher ratio in the image. Referring back to the image, it is true that the image contains both land and sea. In addition, the values of higher red band values indicate that vegetation decreases as their presence can absorb red bands. Large part of the image that are not ocean is developed and built area.\n\n\n\n\n\n\n\n\n\nOther than sentinel products, vegetation indices (VIs) can be optained through different airbourne and satellite platforms with recent advances using Unmanned Aerial Vehicles(UAV). According to (Xue and Su 2017), there are different VIs that have been widely generated in RS applications, yet, due to complexity of different life spectra combinations, instrumentations, there is no unified mathematical expressions to define VIs. Xue and Su (2017) mentioned that the main applications for RS of vegetation are based on the ultraviolet light region (10- 380nm), visible spectra(450-495nm), green(496-570nm), red (620-750nm) wavelength regions, and near and mid infrared ban(850-1700nm). However, for different conditions of vegetations, the observations vary, such as dry plants will have larger range in the emissivity rate, going from 0.88 to 0.94 ; fully grown green plants without any biotic/abiotic stress will be smaller range in emissivity rate, ranging from 0.96-0.99.\nThe generation of VIs are applied to different purposes, such as one of the most commonly used Indices is the Normalise Difference Vegetation Index (NDVI) to characterize canopy growth and compared with Leaf Area Index (LAI). For interpreting the vegetation information, It is common to include validation process through direct or indirect correlations between VIs obtained and the vegetation characteristics of interest measured in situ, such as vegetation cover, LAI, biomass, growth, and vigor assessment. I believe the generation of VIs is a more advanced level than generating the scatter plot to compare B8 against B4 that reflects vegetation , and it should be covered in future weeks. However, at this point, I think the scatter plot is visually more comprehendible for me to understand and interpret about vegetation."
  },
  {
    "objectID": "Week1.html#reflection",
    "href": "Week1.html#reflection",
    "title": "1  Week 1",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nI personally think that remote sensing is way more useful and complicated than it sounds. As I have always focused on learning how to manipulate and wrangle vector data in GIS, I seldom use satellite images as I thought it would only be an image that shows the land features succinctly. However, this practical has definitely made me realized that satellite images could do more than that. I am especially interested with the multispectral bands in the sentinel 2 product. The different combinations of bands could create and reveal different information from an image. Other than the natural colour of B4, B3 and B2, there are many different combination. With knowledge on what land features absorb and reflect, the combinations could create images that allow classifcation of land features in a more detailed manner. For example, colour infrared image of B8, B4 and B3 can reveal healthy and unhealthy vegetation as near-infrared band is good at reflecting chlorpophyll. A Bathymetric image of B4, B3 and B1 is favourable for coastal studies as the coastal aerosol band can estimate suspended sediment in water more accurately. Also, a moisture index image composed of (B8A-B11)/(B8A+B11) can reveal moisture content and perhaps water stress in plants. There are still a lot of combinations of bands, I think it is especially useful for people to gain a brief understanding to a specific area before actually go on a site visit.\n\n\n\n\nAplin, Paul. 2004. “Remote Sensing: Land Cover.” Progress in Physical Geography: Earth and Environment 28 (2): 283–93. https://doi.org/10.1191/0309133304pp413pr.\n\n\nTempfli, Klaus, G. C. Huurneman, Wim Bakker, L. L. F. Janssen, W. F. Feringa, Ambro Gieske, K. A. Grabmaier, et al. 2009. “Principles of Remote Sensing : An Introductory Textbook.” In, 56–85.\n\n\nXue, Jinru, and Baofeng Su. 2017. “Significant Remote Sensing Vegetation Indices: A Review of Developments and Applications.” Journal of Sensors 2017 (May): e1353691. https://doi.org/10.1155/2017/1353691."
  },
  {
    "objectID": "Week2.html",
    "href": "Week2.html",
    "title": "2  Week 2",
    "section": "",
    "text": "3 Summary\nIn week 2, we have learnt concepts of Xanringan and Quarto."
  },
  {
    "objectID": "Week2.html#xaringan",
    "href": "Week2.html#xaringan",
    "title": "2  Week 2",
    "section": "3.1 Xaringan",
    "text": "3.1 Xaringan\n[ʃaː.’ riŋ.ɡan] is an R package for creating slideshows with remark. js through R Markdown.\n\n\n\n\n\nXaringan Logo\n\n\n\n\nIt uses JavaScript library remark.js (https://remarkjs.com) to generate HTML5 presentations of a different style. According to the author of Xaringan, he claims that the name \"xaringan\" came from Sharingan (http://naruto.wikia.com/wiki/Sharingan) in the Japanese manga and anime \"Naruto”. It was meant to be a difficult word to understand and pronounce as the author did not want this style of slideshow to be too popular."
  },
  {
    "objectID": "Week2.html#quarto",
    "href": "Week2.html#quarto",
    "title": "2  Week 2",
    "section": "3.2 Quarto",
    "text": "3.2 Quarto\nan open-source scientific and technical publishing system built on Pandoc. It allows you to publish Python, R, Julia or Observable in a online book or presentation. It combines the functionality of R Markdown, bookdown, distill, and other packages into a single system.\n\n\n\n\n\nQuarto logo. Source:https://www.jumpingrivers.com/blog/quarto-rmarkdown-comparison/"
  },
  {
    "objectID": "Week3.html#summary-of-lecture-3",
    "href": "Week3.html#summary-of-lecture-3",
    "title": "3  Week 3",
    "section": "3.1 Summary of Lecture 3",
    "text": "3.1 Summary of Lecture 3\n\n3.1.1 Correction\nRaw remote sensing images are known to have notable distortions and flaws, which is mainly caused by the curved Earth, incompletely transparent atmosphere, varying solar radiation throughout the day and limitations of instruments. Therefore, most of the raw data captured by remote sensors are preprocessed to remove most of the flaws, it is called Image Correction.\nBelow shows a summary of 4 different correction methods, including Geometric correction, Atmospheric correction, Orthorectification correction and Radiometric correction.\n\n\n\n\n\n\n\n\n\n\n\n3.1.2 Mosaicking images\nIn some cases, some areas we want to observe or the Region of interest (ROI) cannot be completely acquired from a single image, therefore, we would use mosaicking, a procedure to create a new large area image from multiple overlapping images on the same areas. The typical image mosaicking procedure includes 3 steps, including 1) tonal adjustment 2) seamline detection, and 3) image blending. In R, the function of “mosaic()” does the whole process in 1 line to form a new object with a larger spatial extent. We can specify which function to use such as mean, minimum and maximum value for output.\n\n\n3.1.3 Corrections in Hong Kong\nIn this practical, I have chosen 4 tiles that consist parts of Hong Kong, including 1 Landsat 8 tile and 3 Landsat 9 tiles. However, as the tiles are with 2 different coordinate reference system of EPSG:32650 for two of them and EPSG:32649 for the remaining two tiles. I have tried using different methods to reproject rasters into the same projection (EPSG: 32649), however, the resolutions for the images are different from each other with 30.03617, 30.03617 (x, y) and 30.05118, 30.05118 (x, y). Hence, with limimte time and I couldn’t figure how to alter resolution to create a mosaic image with 4 raster images. I decided to only used two of tiles to create mosaic image of the Pearl River Delta whicn includes also Hong Kong. It works fine considering Hong kong is a really small area and can fit well with two of the images.\n\n\n\n\n\n\n\n\n\nBelow shows a summary of the initial obtained image of the mosaic image, which are bands of Landsat 9. Landsat 9 is similar to Landsat 8, but is designed to image four visible spectral bands, one near-infrared spectral band, three shortwave-infrared spectral bands at 30 m (98 ft) spatial resolution, and one panchromatic band at 15 m (49 ft) spatial resolution, and two thermal bands at 100 m (328 ft) spatial resolution. In this practical, band 8 of the spectral bands are not used. Band 1 is used specially to measure chlorophyll concentrations, band 9 is used to detect cirrus clouds by measuring light in the part of the electromagnetic spectrum where the clouds are most visible.\n\n\n\n\n\nBands of created image"
  },
  {
    "objectID": "Week3.html#application",
    "href": "Week3.html#application",
    "title": "3  Week 3",
    "section": "3.2 Application",
    "text": "3.2 Application\n\n3.2.1 Image Enhancment with the mosaicked images in Hong Kong – NDVI\nSome of the basic image enhancements were done in this practical. As numerous remote sensing applications such as mapping, classification, soil moisture detection require high resolution and high quality images, therefore , the raw remote sensing images can be enhanced by improving the contrast and edge information of the input image. I have followed the steps in the practical to create the Normalised Difference Vegetation Index (NDVI) for the images around Hong Kong. It is calculated from the visible and near-infrared light reflected by vegetation where healthy and green vegetation reflects more in the NIR and absorbs in the Red wavelength. The land surfaces shown below are mostly yellowish (0.2-0.4) in colour, except where the delta lies in the middle. The colour scheme for the red circled area (Hong Kong) displayed shows gradual change from yellow to green (>0/4). The green areas are mostly green spaces are hills in Hong Kong.\n\n\n\n\n\nthe NDVI index for Pearl River Delta.\n\n\n\n\nThe index between 0.2-0.4, which is shown in yellow colour here, refers to the presence of sparse vegetation while value above 0.4 refers to moderate to high density of vegetation. The lower figure has pulled out areas with vegetation, where NDVI values are set to equal or above 0.2. I think it is effective to generate different indexes to identify different land features, then create filters with certain value to pull out the features more precisely.\n\n\n\n\n\nthe vegetation for Pearl River Delta.\n\n\n\n\n\n\n3.2.2 Different Indices for image enhancement\nThe table below shows some other different indices and corresponding equations for different features’ identification, such as water, geology and landscape indices. I think this makes remote sensing a very useful tool as it helps identify different land features easily.\n\n\n\n\n \n  \n    Image Indices \n    Equation \n  \n \n\n  \n    Modified Soil Adjusted Vegetation Index (MSAVI2) \n    MSAVI2 = (1/2)*(2(NIR+1)-sqrt((2*NIR+1)2-8(NIR-Red))) \n  \n  \n    Soil-Adjusted Vegetation Index (SAVI) \n    SAVI = ((NIR - Red) / (NIR + Red + L)) x (1 + L) \n  \n  \n    Normalized Difference Snow Index (NDSI) \n    NDSI = (Green - SWIR) / (Green + SWIR) \n  \n  \n    Modified Normalized Difference Water Index (MNDWI) \n    MNDWI = (Green - SWIR) / (Green + SWIR) \n  \n  \n    Normalized Difference Moisture Index (NDMI) \n    NDMI = (NIR - SWIR1)/(NIR + SWIR1) \n  \n  \n    Clay Mineral Ratio \n    Clay Minerals Ratio = SWIR1 / SWIR2 \n  \n  \n    Ferrous Minerals Ratio \n    Ferrous Minerals Ratio = SWIR / NIR \n  \n  \n    Iron Oxide Ratio \n    Iron Oxide Ratio = Red / Blue \n  \n  \n    Burn Area Index (BAI) \n    BAI = 1/((0.1 -RED)^2 + (0.06 - NIR)^2) \n  \n  \n    Normalized Burn Ratio Index (NBRI) \n    NBR = (NIR - SWIR) / (NIR+ SWIR) \n  \n  \n    Normalized Difference Built-up Index (NDBI) \n    NDBI = (SWIR - NIR) / (SWIR + NIR) \n  \n\n\n\n\n\n\n\n3.2.3 Texture analysis\nThe next interesting thing of this practical is the texture analysis. Image texture is generally considered as the change and repeat of image grey in space, by adding texture information to the original spectral information of the image can improve the correction and precision. Image texture is the quantification of intuitive qualities described by terms such as rough, smooth, silky, or bumpy as a function of the spatial variation in pixel intensities. I used band 4 (red) and band 5(NIR) for texture analysis illustration, Grey Level Co-occurrence Matrices (GLCM) is adopted to describe the basic cell of texture orrandom and spatial statistic character in local pattern. To find texture features from GLCM for texture classification, the criteria of Homogeneity is adopted, which measures the closeness of the distribution of elements in the GLCM to the GLCM diagonal. Some other possible criteria such as Energy, Entropy, Contrast etc. This is the result for GLCM in homogeneity in the image, it shows that most of the area is close to 1, especially for ocean, while at the peak or higher area, the image shows more with pink to orange colour. the green colour region, which is ocean in this case, are smoother while the areas with pink to orange colour, they are dispersed and disconnected, it is more rough, probably, they are with vegetation and not uniform elevation and texture.\n\n\n\n\n\nTexture\n\n\n\n\n\n\n3.2.4 Principal Component Analysis (PCA)\nThis is the result for the Principal Component Analysis in Hong Kong. PCA analysis aims to reduce dimensionality of the data, and in the figure below, it shows how the components varies and are similar to each other in PC 1 band of the image. Also the table below displays the whole statistics of the 9 components with standard deviation, variance and cumulative proportion. The highest variance is component 1, constituting 79% meaning that the more important this component is.\n\n\n\n\n\nPC1 of PCA analysis result\n\n\n\n\n\n\n\n\n\n\n\n\n\nComponent 1\n\n\nComponent 2\n\n\nComponent 3\n\n\nComponent 4\n\n\nComponent 5\n\n\nComponent 6\n\n\nComponent 7\n\n\nComponent 8\n\n\nComponent 9\n\n\n\n\n\n\nStandard deviation\n\n\n2.6720079\n\n\n0.8317190\n\n\n0.7078958\n\n\n0.5985590\n\n\n0.4424598\n\n\n0.2908058\n\n\n0.1294195\n\n\n0.1008848\n\n\n0.0442961\n\n\n\n\nProportion of Variance\n\n\n0.7932918\n\n\n0.0768618\n\n\n0.0556796\n\n\n0.0398081\n\n\n0.0217523\n\n\n0.0093964\n\n\n0.0018610\n\n\n0.0011309\n\n\n0.0002180\n\n\n\n\nCumulative Proportion\n\n\n0.7932918\n\n\n0.8701536\n\n\n0.9258332\n\n\n0.9656413\n\n\n0.9873936\n\n\n0.9967901\n\n\n0.9986511\n\n\n0.9997820\n\n\n1.0000000\n\n\n\n\n\nSummary of PCA analysis\n\n\nPCA and Texture analysis are applied in various researches. The principal components (PCs) obtained by PCA are linearly independent and are sorted by variance in descending order. An iconic application of PCA is deforestation monitoring by"
  },
  {
    "objectID": "Week3.html#reflection",
    "href": "Week3.html#reflection",
    "title": "3  Week 3",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nCorrection in satellite images are very important, because there are actually many error source, such as geometric, radiometric, atmospheric errors that cannot be avoided. For example, a satellite that travels in an orbit with an angle of 30 degree will always take image in that angle, hence, creating a skewed image that requires correction before using it for analysis or research purpose. I also think that texture analysis is"
  },
  {
    "objectID": "Week4.html#summary-of-lecture-4",
    "href": "Week4.html#summary-of-lecture-4",
    "title": "4  Week 4",
    "section": "4.1 Summary of Lecture 4",
    "text": "4.1 Summary of Lecture 4\n\n4.1.1 City — Madrid, Spain\nClimate change is a global phenomenon, yet affects different countries and places at different rate. While global warming is not a globally uniform warming phenomenon, some regions are affected at greater level.\n\n\n\n\n\nTemperture difference in 2020 compared to 1981-2010 average. Source:ERA5.https://climate.copernicus.eu/copernicus-2020-warmest-year-record-europe-globally-2020-ties-2016-warmest-year-recorded\n\n\n\n\nThe figure above shows the temperature difference in 2020 compared to the average temperature in 1981-2020. The large variations in temperature difference in different regions indicated that climate change has unequal effects on temperature globally. Global Climate Risk Index is an index generated by Germanwatch, it analyses quantified impacts of extreme weather events and ranks countries according to the level of exposure and vulnerability to extreme events. The long-term Global Climate Risk Index (CRI) published in 2021 examines global data from 2000-2019, Spain ranked 29 out of 180 countries. with CRI score of 46.50. This risk score indicates a relatively lower risk to other countries because lower risk scores have higher risk to climate impacts, such as Puerto Rico ranked 1st with risk score of 7.17.\nSpain is getting warmer and drier than previous decades, the Meditarranean region in Spain has increased by 1.5 degree Celsius, which is more than global average increase of 1.1 degree Celsius. The figure below shows the spatial patterns of temperature observations and simulations with TX90 index of Spain, where TX90 indicates the percentage of warm days when daily max temperature > 90th percentile. The third row of the figure shows changes in projected TX90 index (% of days) for the period 2021–2050 concerning the period 1971–2000 for both scenarios Lorenzo and Alvarez (2022). The grey dots mark the areas where changes are significant at the 5% significance level from the Wilcoxon ranksum test Lorenzo and Alvarez (2022).\n\n\n\n\n\nspain temperature projection. Source: https://link.springer.com/article/10.1007/s11069-022-05306-x\n\n\n\n\nThe temperature that exceeds 35ºC in July 2021 in Spain was shown in the GIF below. A meteorologist for the State Meteorological agency (AEMET) stated that large parts of the peninsula will enter one of the hottest regions on the surface of the planet. It will be an extension of the traditional summer ‘heat belt’ that usually extends from Algeria to India Benayas (2021). For Madrid, it has increased 2°C in the past 30 years, the maximum summer temperatures are on average higher than 38°C and the city is suffering from longer and more frequents heatwaves. In order to mitigate and combat climate change, different approaches regarding to different city context are proposed.\n\n\n\n\n\nA map of the areas that will reach or exceed 35ºC between Friday and Monday in July, 2021. Source: https://english.elpais.com/spain/2021-07-09/spain-braces-for-extreme-weekend-heat-with-temperatures-set-to-top-44c.html\n\n\n\n\n\n\n4.1.2 Policy: “El Bosque Metropolitano”\n“El Bosque Metropolitano” is an urban redevelopment programme implemented by the City Council of Madrid. Winning proposal from competitions hosted for Metropolitan Foest is used as a feasible way in developing the Metropolitan forest. The aim of this programme is to combat climate change by building a 75km-long metropolitan forest in the city. The forest construction will contribute to the rebalancing of the city, reducing of CO2 emissions, improving air quality, decreasing desertification and flood risks, support biodiversity, and act as a thermal regulator for the city as it will mitigate Madrid’s urban heat island. It is a long-term city project that will take about 12 years to complete. When this forest reaches maturity, it will potentially be able to absorb 170,000 tons of CO2. The proposed plan would not only alleviate the impacts brought by climate change, but will also benefit in nature and social aspects. It will facilitate ecological and landscape restoration of degraded areas and increasing pedestrian and cycling routes, as well as benefiting the health of the population.\nThe proposed plan is to create environmental belt around Madrid’s perimeters with new parks, children’s zones, dog trails and hiking and biking routes for city-dwellers and tourists. It will be a forest belt encircling the city. The Strategic Planning of the Madrid Metropolitan Forest is shown below.\n\n\n\n\n\nStrategic Planning of the Madrid Metropolitan Forest. Source: https://mymodernmet.com/madrid-urban-forest/\n\n\n\n\nThe existing woodlands in the northern part will be connected with green metropolitan rings in the south and east parts as they appear to have fewer spaces and less connected. The authority considered the southern part as a great opportunity to make interconnected green infrastructure. The first phase will take place in areas that allow immediate interventions including Vicálvaro and Villa de Vallecas.\nWhile this is a long-term policy that is expected to finish in 12 years, various uncertainties and challenges are faced on implementing different phases of greening in the city. Hence, remote sensing techniques can be used to identify and provide suggestions in combating these challenges."
  },
  {
    "objectID": "Week4.html#application",
    "href": "Week4.html#application",
    "title": "4  Week 4",
    "section": "4.2 Application",
    "text": "4.2 Application\n\n\n\n\n\n5 crowns of the Forest development. Source: https://bosquemetropolitano.madrid.es/bosque-del-manana/\n\n\n\n\nWith existing urban and rural structures, the development plan is divided into 5 crowns based on the characteristics of the area. The 5 areas are:\n\n\n\n\n \n  \n    Division \n    Focus \n    Priority Objective \n  \n \n\n  \n    1 \n    Among Natural Forest \n    Connections of the El Pardo mountain with that of Valdelatas and Casa de Campo. Continuity of the fluvial axis of the Manzanares river. \n  \n  \n    2 \n    Uniting Urban Parks \n    Connections of the system of metropolitan open spaces, Valdebebas, Fairgrounds, O'Donnell Wedge, Vicalvarada, Valdebernardo and Cerro Almodóvar with the New Centrality of the East. \n  \n  \n    3 \n    Green Ring of Southeast \n    Valuation of the systems of free spaces of the growths of the southeast, from the Cerro de la Herradura to the Cantiles del Manzanares. \n  \n  \n    4 \n    River Parks of the South \n    Connections of the fluvial systems of the Manzanares river and La Gavia stream with the integration of large peripheral pieces of free spaces in Entrevías, La Atalayuela, Mercamadrid and Butarque. \n  \n  \n    5 \n    The Metropolitan Ring \n    Integration of the southwest metropolitan system (Getafe, Leganés, Alcorcón) with Casa de Campo. Valuation of fluvial environments of the Meaques stream. \n  \n\n\n\n\n\nWhile the project does not only combat climate change, but also on air quality and improve the living environment of the city, comprehensive and cautious assessment should be carried out before implementing any measures. Remote sensing is an ideal tool for conducting various analysis and monitoring a large scale urban forestry project. In this context, there are 5 different regions that could adopt remote sensing differently in aid to the project’s objectives.\n\n4.2.0.1 Area 1: Among Natural Forest\nFirst, for area 1, that is to connect a peri-urban space of 1,400 ha to the high valuable forests of El Prado, Valdelatas mountains and Casa de Campo. The area acts as a transitional space between the nature to existing urban parks, making environmental protection compatible with walks and healthy leisure activities. Hence, remote sensing for biodiversity in the forests in the north, distinguishing species, or identify species of individual trees (Turner et al. 2003). The information of the diversity pattern , especially on the fringe could be used to determine types of trees, and the density of trees to be planted so as to conserve species and lower impacts on local ecosystem, simultaneously, helping the design of infrastructures such as walks, experimental farms and leisure activities in the transitional space. For example, Polyakova et al. (2023) has used Sentinel-2 Satellite Data in automated recognition of tree species in Raifa forest, Russia. The reflectances of tree species are observed in the red-edge (Band 6, Band 7) and near-infrared (Band 8, Band 8a) bands in all images. The image below shows the classification of tree specices using sentinel-2 level2A images.\n\n\n\n\n\nSentinel-2 data classification results: (a) RF method; (b) GTM method. Source: https://www.mdpi.com/2072-4292/15/2/329\n\n\n\n\n\n\n4.2.0.2 Area 2: Uniting Urban Parks\nWhile for area 2, large parks in Madrid are often disconnected with the presence of infrastructures. Hence, the main objective is to connect green spaces of the general system of free spaces with a forest avenue that will have a bike path and a large walking area that will unite all the large parks of our city. As urban green spaces should be constructed in a hierachical structure, where vegetations in different areas contains different social functions, such as public parks, residential green space, green buffer. Remote sensing images can identify different social functions of different vegetation patches with spectral analysis to vegetation and non-vegetation areas. Hence, the extent of disconnected green spaces in aid with functions of existing green spaces can be used to determine the density of trees and types of greening to implement, such as ecoducts that allow cyclist and pedestrians movement. This way, the urban structures and urban functions of the original areas could be retained while greening is built on.\n\n\n\n\n\nVegetation types (a–c) and vegetation patches with various social functions (d–h) in satellite images. Source: https://www.sciencedirect.com/science/article/pii/S0924271618302910\n\n\n\n\n\n\n4.2.0.3 Area 3: Green Ring of Southeast\nIn the southeast of Madrid, the specific physical environment makes vegetation more challenging to establish. The main objective is to value the free spaces of the new growths of the southeast. Arid soil in the area can be captured with remote sensors for soil analysis, the variations in soil properties within the large areas can imply the specific type of vegetation and soil conservation measures in order to successfully establish roots in the varying arid soils, hence connecting to the fertile valleys of Manzanares and Jarama. Soil parameters including soil moisture, roughness, temperature and texture could be retrieved through both active and passive remote sensing. For active remote sensing, sensors like Synthetic Aperture radar (SAR) are more focused on local and regional studies with high resolution images, while scatterometers are more adopted for global estimations of soil properties (Zribi, Baghdadi, and Nolin 2012). For passive remote sensing, Landsat, ASTER are more use for vegetation cover description, land use analysis, hyperspectral sensors provides soil texture description and thermal infrared band are adapted for soil temperature estimation (Zribi, Baghdadi, and Nolin 2012).\n\n\n4.2.0.4 Area 4: River Parks of the South\nThe creation of an agricultural park is planned to enhance the fertile plain of the Manzanares, which will be complemented with equipment in the area of ​​the fourth lock, called the farmer’s house. The essential resources for establishing forests can be retreived through remote sensing such as temperature variations, soil properties, water resources, solar radiation variability. Passive remote sensing could be adopted in this sense to capture the illumination hour of solar radiation on the area. Thus, with the information, trees could be planted in a cautious manner to aid sustainable forest management, such as preventing erosion or the accumulation of runoff water from the surrounding hills to increase the flow of the river. The planting of trees does not only improve the air quality and physical environment, but also regulating the water cycle indirectly.\n\n\n4.2.0.5 Area 5: The Metropolitan Ring\nThe main objective for this area is to create a green space between the neighboring municipalities supported by infrastructure borders, the Butarque stream and the large Campamento land reserve. This area’s forestation will demand more on serving the neigbouring population and neighboring municipalities supported by infrastructure borders. The purpose of trees plantation in this area is to create an ecological restoration center and a equipment dedicated to a business incubator that promotes the green economy model. Hence, remote sensing could do similar work to the other areas to create a plan that benifits the envionrment, economy and society functionings. One of the possible ways is to implement street tree planting with precise locations or developing vertical plantations that helps alleviate high urban temperature area using remotely sensed thermal infrared data for land surface temperature (LST) to detect urban heat island effects to the urban areas within the area (Keeratikasikorn and Bonafoni 2018). Then, the correspond surface urban heat island (SUHI) map can be generated to compare with the previous Land plan maps to identify places that are required to plant trees (Keeratikasikorn and Bonafoni 2018).\n\n\n\n\n\nSUHI maps of Bangkok urban area obtained by the seven Landsat 8 clear-sky images. The last map represents the mean SUHI of the seven images. Source: https://www.mdpi.com/2072-4292/10/3/440\n\n\n\n\nRemotely sensed data can be used in different ways to generate essential information corresponding to the objectives of a certain area. In general, data for air quality, land cover classification, heat index, soil parameters are common criteria for solving challenges for the implementation of metropolitan forests in Madrid."
  },
  {
    "objectID": "Week4.html#reflection",
    "href": "Week4.html#reflection",
    "title": "4  Week 4",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nClimate change is an imminent problem faced by the globe, the impacts brought by is definitely not only by the rise of surface temperature, but also harming the balance of the world such as extreme natural hazards, heat waves and dangerous weathers that threaten lives on earth. I think the metropolitan forest plan brought up in Madrid is a very direct action responding to climate change as growing trees remove carbon dioxides and increased carbon sink, bringing immediate benefits to the society and climate. I think remote sensing could contribute a lot in policies like this as it provides crucial visualisation that reveal the potentials and the basis of an urban area, hence can act as a guidance for constructing a feasible plan to implement within urbanised land. However, one concern that comes to mind is the sustainability and maintenance of the urban forests. Regular and attentive monitoring on the growth of trees is a requisite element because of various possibilites. For instance, the growing conditions in urban environment can be hard, such as pollutants, limited space above and below ground that inhibit growth. Also, encroachment to development can also occur, where roots of trees could cause structural damage to buildings, and in extreme cases, harming the foundations of buildings. Hence, I think a large scale urban forest plan should have more frequent assessment and monitoring so as to prevent and maintain a stable conditions for both urban and nature.\n\n\n\n\nBenayas, Victoria Torres. 2021. “Spain Braces for ‘Extreme’ Weekend Heat with Temperatures Set to Top 44ºc.” https://english.elpais.com/spain/2021-07-09/spain-braces-for-extreme-weekend-heat-with-temperatures-set-to-top-44c.html.\n\n\nKeeratikasikorn, Chaiyapon, and Stefania Bonafoni. 2018. “Urban Heat Island Analysis over the Land Use Zoning Plan of Bangkok by Means of Landsat 8 Imagery.” Remote Sensing 10 (3): 440. https://doi.org/10.3390/rs10030440.\n\n\nLorenzo, M. N., and I. Alvarez. 2022. “Future Changes of Hot Extremes in Spain: Towards Warmer Conditions.” Natural Hazards 113 (1): 383–402. https://doi.org/10.1007/s11069-022-05306-x.\n\n\nPolyakova, Alika, Svetlana Mukharamova, Oleg Yermolaev, and Galiya Shaykhutdinova. 2023. “Automated Recognition of Tree Species Composition of Forest Communities Using Sentinel-2 Satellite Data.” Remote Sensing 15 (2): 329. https://doi.org/10.3390/rs15020329.\n\n\nTurner, Woody, Sacha Spector, Ned Gardiner, Matthew Fladeland, Eleanor Sterling, and Marc Steininger. 2003. “Remote Sensing for Biodiversity Science and Conservation.” Trends in Ecology & Evolution 18 (6): 306–14. https://doi.org/10.1016/S0169-5347(03)00070-3.\n\n\nZribi, Mehrez, Nicolas Baghdadi, and Michel Nolin. 2012. “Remote Sensing of Soil.” Applied and Environmental Soil Science 2011 (January): e904561. https://doi.org/10.1155/2011/904561."
  },
  {
    "objectID": "Week5.html#summary-of-lecture-5",
    "href": "Week5.html#summary-of-lecture-5",
    "title": "5  Week 5",
    "section": "5.1 Summary of Lecture 5",
    "text": "5.1 Summary of Lecture 5\n\n5.1.1 Basics of Google Earth Engine (GEE)\nGoogle Earth Engine (GEE) is a cloud-based geospatial processing platform that uses Javascript. It was introduced in 2010 by Google, allow users to conduct geospatial analysis at scale, which includes access to a large warehouse of satellite imagery and the prompt computational power needed to analyze those images. Below shows a comprehensive navigation guide to different tabs of the GEE layout.\n\n\n\n\n\nGEE layout. Source:https://ourcodingclub.github.io/tutorials/earth-engine/\n\n\n\n\nCodes that run on the browser is called the Client Side, while codes that run on the server where data is stored is called Server Side. I think it is very useful to get to know more about the Java script style, including the data types, Earth Engine Objects (ee.object), and functional programming like For loop on the official Google Earth Engine Guide. During the lecture, it was specially mentioned that a loop is not possible to execute over the contents of an ee. ImageCollection because it is on the server side. Instead, a better option would be using the map() throughcreating a function that can be independently applied to each element. The figure below illustrates a simplified example of how map() would be better than for-loops in. GEE."
  },
  {
    "objectID": "Week5.html#application",
    "href": "Week5.html#application",
    "title": "5  Week 5",
    "section": "5.2 Application",
    "text": "5.2 Application\n\n5.2.1 Melbourne in GEE\nI used Melbourne for this practical. I downloaded the GADM boundary for Australia from GADM. The original intention was to select Tasmania, however, the available imagery for the location is very limited, I adjusted several filters including the date and cloud cover to include larger range of imagery in the area:\n{< .filterDate(‘2017-01-01’, ‘2022-10-10’)>} {< .filter(ee.Filter.lt(“CLOUD_COVER”, 0.5));}\n\n\n\n\n\nTasmania\n\n\n\n\nHowever, the imagery shown are not sufficient, the screenshot below shows the coverage for Tasmania was not complete. Hence, I have selected other locations with more complete coverage of imagery. I found Melbourne with fulle coverage image, hence I chose it as the city for exploration in GEE. The figure below shows the True Colour Image that is clipped to SA boundary.\n\n\n\n\n\nTrue COlour Image of South Australia\n\n\n\n\nI have mosaiced the image collection, and with the overlapping pixels, I took the mean to create less obvious demarcation of image overlap. Then, I clip it back with Melbourne boundary.\n\n\n\n\n\nMosaicking and Clipping of images from South Australia\n\n\n\n\n\n\n5.2.2 Texture analysis of Melbourne\nGEE has several methods to estimate spatial texture, image.entropy() can be used when the image is discrete valued to compute the entropy in a neighbourhood. Other than that, another method is a familiar method with gray-level co-occurrence matrix (GLCM). glcmTexture() however works with integer value, hence, the value in surface refectance will be converted to integers, which is 1 and 0 in this case, as shown in the histogram below. The range is too subtly small. therefore, it has to be multiplied so the texture can be computed with the following codes.\n\nvar glcm = clip.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7])\n  .multiply(1000)\n  .toUint16()\n  .glcmTexture({size: 1})\n  .select('SR_.._contrast|SR_.._diss')\n  .addBands(clip);\n\n\n\n\n\n\n7 bands’pixel value\n\n\n\n\nThe GLCM considers spatial relationships of pixels in an image, I used the statistics of contrast GLCM for Melbourne, measuring the local variations in the gray-level co-occurrence matrix. The lower contrast areas(dark purple to black) are mainly natural environment and forestry, while the high contrast area (pink to light purple) are urban areas, such as settlements, urban structures. There is a comparison below between the glcm map and the tci image.\n\n\n\n\n\nContrast GLCM\n\n\n\n\n\n\n5.2.3 PCA analysis of Melbourne\nPrinciple Component analysis(PCA) transforms the original vector image data into smaller set of uncorrelated variables such, allowing the identification of standards in data and their expression to emphasise the similarities and differences (Santo 2012). From the 21 element of the PCA analysis, the first 4 components are shown as they explain for cumulative 98.68% of total variance within the whole image collection. The variation captured in Melbourne is quite obvious as the different land use tend to form a cluster, the urban areas are located around the coast while the inner regions are mostly natural environment with less significant clusters of settlements.\n\n\n\n\n\nPCA\n\n\n\n\n\n\n5.2.4 Band math in GEE\nGEE also supports band math generation, I have illustrated with Normalized Difference Vegetation Index(NDVI) and Normalized Difference Water Index (NDWI) with simple lines of code.\n\n//NDVI\nvar NDVI_1 = clip.select('SR_B5').subtract(clip.select('SR_B4'))\n  .divide(clip.select('SR_B5').add(clip.select('SR_B4')));\n\nMap.addLayer(NDVI_1, { min: -1, max: 1, palette: ['blue', 'white', 'green']}, 'NDVI');\n\n\n\n\n\n\nNDVI of Melbourne\n\n\n\n\n\n//NDWI\nvar NDWI = clip.select('SR_B3').subtract(clip.select('SR_B5'))\n  .divide(clip.select('SR_B3').add(clip.select('SR_B5')));\n\nMap.addLayer(NDWI, { min: -1, max: 1, palette: ['blue', 'white', 'green']}, 'NDWI');\n\n\n\n\n\n\nNDWI of Melbourne\n\n\n\n\nIn this practical, some basic tasks and analysis were performed with remote sensing data, however, there are more advanced applications with GEE, such as natural resource management through detecting trends of natural and human phenomenon to understand the correlations. Hence, using th information generated, it could be applied to organisations and governments for better sustainable management, such as forests and water (“Introducing Earth Engine for Governments and Businesses” 2022). For instance, a company called Regrow used GEE to generate granular field data at state or country level across millions of acres of farmlands around the world to help them decarbonize their agricultural practices (“Introducing Earth Engine for Governments and Businesses” 2022). GEE enable regenerative and reproducible technique to be applied to different contexts. I think companies using GEE could be a good approach because they have access to very large datasets and the capability of the company to provide services or products are larger because with the large range of dataset, they can cover different natural, social and economic aspects, such as producing predictions, pattern and analysis on a phenomenon."
  },
  {
    "objectID": "Week5.html#reflection",
    "href": "Week5.html#reflection",
    "title": "5  Week 5",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nGEE is very new and interesting to me, I am surprised of the capability of GEE in remote sensing. Other than the confusion with JavaScript, I think GEE in general is a very useful tool for carrying out large scale geospatial analysis. In this practical, I got to explore Melbourne by creating various parameters such as texture, PCA and band maths. I think that the GEE window is sometimes hard to navigate because if there is a variable viewer automatically, and rather than requiring users to use print() function to write in console. With a variable viewer, it would be more convenient and easily understandable about what I have created because I sometimes get confused about how to interpret the maps and want to go back to check values of the layer. Also, I am still figuring out a way to create legend to collate for interpretations on maps.\nIn general, I think GEE is a pragmatic tool but perhaps the errors could be more comprehendible for users to debug. I do think that the large dataset available on a cloud-based platform is awesome and I really like the “Google Earth Timelapse” on GEE. I saw the timelapse displaying the urban growth in Naypytaw, Myanmar from 1984 to 2020 is simply amazing.\n\n\n\n\n“Introducing Earth Engine for Governments and Businesses.” 2022. https://blog.google/products/earth/introducing-earth-engine-for-governments-and-businesses/.\n\n\nSanto, Rafael do Espírito. 2012. “Principal Component Analysis Applied to Digital Image Compression.” Einstein (São Paulo) 10 (June): 135–39. https://doi.org/10.1590/S1679-45082012000200004."
  },
  {
    "objectID": "Week6.html#summary-of-lecture-6",
    "href": "Week6.html#summary-of-lecture-6",
    "title": "6  Week 6",
    "section": "6.1 Summary of Lecture 6",
    "text": "6.1 Summary of Lecture 6\nThis is the second lecture that covers Google Earth Engine (GEE), and it is more focused on image classification. Before going deep into what image classification refers to in technical terms, this lecture focused on how classified images are used in different contexts to solve various problems, also introducing machine learning in remote sensing. To briefly understand the term image classification, it refers to the process of identifying and categorising images according to their appearances or pixels, it is an imperative process before actually analyzing them in research or studies because the classified images provides concrete information of the classes captured in an image.\n\n6.1.1 Machine learning in remote sensing with GEE\nMachine learning has been applied in remote sensing for various usage, including image classification, regression, clustering, coding and source separation. In the lecture, Classification and regression trees (CART) was introduced. The two types of decision trees are:\n\nClassification trees (CA) : classify data into ≥ 2 discrete categories\n\nexamples: temperature. rainfall, wind, saturation\n\nRegression trees (RT) : predict continuous dependable variables\n\nexamples: age, height, score\n\n\n\n6.1.1.1 Classification trees\nThe CART algorithm was published by Leo Breiman in 1984, using decision tree to provide more information to learn from in the form of basic if-else-decision rules. The decision tree is a simple structure that consist of different kinds of elements, a starting point (Root), decision nodes and multiple terminal nodes (Leaves). Eventually, each pixel points will be assigned to class for classification purpose. In other words, classification trees tries to subset data into smaller chunks, it is useful when linear regression does not fit, by subseting the original data, the classification tree can generate different category.\n\n\n\n\n\nKnowledge-based decision tree. Source: https://www.mdpi.com/2072-4292/4/6/1741\n\n\n\n\nThe concept of decision tree is easily grasped, hence, it is rather easy to employ in different analysis. Also, as it can be visualised, people that works better with visualisation in problem solving will benefit from it. However, on the downside, decision tree are prone to overfitting, causing more complex trees fail to properly generalise data. Also, there is the possibility that the final leaves result with a mixture of different categories –> Impurity.\nTo solve the impurity for clear classification, the Gini Impurity is quantified and used as splitting methods, where it measures the likelihood of an incorrect classification of a new instance of a random variable. The Gini Impurity formula is calculated as:\n\\[\nG=i=1∑C​p(i)∗(1−p(i))\n\\]\nTwo other common impurity metrics are Entropy:\n\\[\nIe(S) = −∑pilog2(pi)\n\\]\nand Missclassifcation error:\n\\[\nIc(S) =1 – max(pi)\n\\]\nGini index and entropy behave similarly,both attempting to reach a unique maximum, though at slightly different positions. Gini Impurity of 0 is the lowest and best possible impurity, but it only occurs when all the pixels are in the same class. While for misclassification error, it is simply the fraction of points in the subset that are not in the major vote class, it’s more of pruning nature and not growing a tree.\n\n\n6.1.1.2 Regression trees\nDifferent from classification trees, regression trees are used when the response variable is continuous. With many predictor variables, the decision trees can undergo trials of different thresholds and calculate the sum of squared residuals (SSR). It helps to predict continuous variables such as amount of pollution. The figure below shows major difference of regression tree and classification tree.\n\n\n\n\n\nClassifcation vs Regression . Source: https://www.javatpoint.com/regression-vs-classification-in-machine-learning\n\n\n\n\nThe normal workflow for a regression tree is in the first split, compare and find the lowest average value, then consider another split, find the lowest value again and so on.\n\n\n6.1.1.3 Random Forest\nIn classification of new data, using one decision tree is not ideal, because it is not that accountable. However, with many trees, that form a forest, there are more decision trees to increase accuracy and accountability. In addition to our data, boostrap samples are taken, then create a decision tree from random number of variables.\n\n\n\n\n\nRandom forest classifier . Source: https://www.freecodecamp.org/news/how-to-use-the-tree-based-algorithm-for-machine-learning/\n\n\n\n\nIt is a tree-based supervised learning algorithms by combining hundreds decision trees and train each tree on a different sample of the observations. Bootstrapping is a resampling method by replacing data to make a decision, which is called Bagging. So what exactly does the two terms mean?\nBootstrapping : A resampling technique that involves random sampling of a dataset with replacement; allowing generation of new samples from a population without having to go and collect additional “training data”. However, a major drawback of decision trees is being high-variance estimators, meaning that the addition of small number of training observations could alter the prediction of a learned tree. Therefore, bagging or bootstrap aggregation can be used to mitigate the problem\nBagging: Combine multiple learners that have fitted on separate bootstrapped samples and average the predictions. This effectively reduce overall variance of the predictions. In random forests, bagging helps to decrease the correlation between each decision trees and thus increasing its predictive accuracy.\n\n\n\n\n6.1.2 Classification in Antwerpen\nIn this practical, I chose Antwerpen to try and apply with the aforementioned classifications and machine learning in GEE. Instead of uploading the shapefile, the GAUL global admin layers and level 2 in GEE’s catalog was used. Antwerpen is filtered out. Using Sentinel 2 MSI level 2A , I filtered the entire collection based on a low cloud coverage percentage of 5% per tile within the time period of 2022-01-01 to 2022-10-31. Below shows the gif the satellite image of Antwerpen by increasing the cloud coverage, but using the masking function to mask the cloud pixels. The cloud cover has significantly reduced with the mask in my case.\n\n\n\n\n\nCloud cover mask in Antwerpen\n\n\n\n\nTo classify Antwerpen with s supervised model, the training dataset has to be selected. I have used 6 category including\n\nUrban area (low)\nUrban area (high)\nBare earth\nWater\nGrass\nForest\n\nI have used the geometry function to select some of the areas that conform to the category, the figure below shows some examples of how the training data is selected.\n\n\n\n\n\nTraining examples\n\n\n\n\nThen, the next step is to train the CART classifier with the training data set, and use that for classifying image.\n\n\n\n\n\nTraining examples\n\n\n\n\nIn the figure, purple represents water,light pink refers to urban area (low), darker pink refers to urban area (high), however, dark green refers to forest, however, some of the bare earth is also classified into dark green, and grass to be in light grey colour.\nUnfortunately, the validation results are horrible, with :\n\n\n\n\n\n\n\nValidation error matrix:\n0: [0,0,0,0,0,0,0]\n1: [0,0,0,4168,332,0,0]\n2: [0,0,0,0,0,0,0]\n3: [0,0,0,0,0,0,0]\n4: [0,0,0,0,0,0,0]\n5: [0,0,2,975,936,0,0]\n6: [0,0,156,29231,29964,0,0]\n\n\nValidation overall accuracy\n0\n\n\nValidation consumer accuracy\n[[0,0,0,0,0,0,0]]\n\n\n\nThe bad results are due to the train test split was done on the polygons but not on the original pixels, since I have only included a few polygons for each category, the validation results would turn out ridiculous.\n\n6.1.2.1 Classify image with pixel approach\nInstead, I have referred to the practical’s code that is credited to Ollie Ballinger to make the train test split using a pixel approach. The validation results this time is\n\n\n\n\n\n\n\nTraining overall accuracy\n0.996415770609319\n\n\nValidation overall accuracy\n0.8683195592286501\n\n\nValidation consumer accuracy\n0: 0\n1: 0.7993630573248408\n2: 0.9935897435897436\n3: 0.7927272727272727\n4: 0.8282828282828283\n5: 0.9265175718849841\n6: 0.8585526315789473\n\n\nOutOfBafErrorEstimate\n\n0.12258064516129032\n\n\n\n\n\n\n\n\nTraining examples\n\n\n\n\nAnd this is the final output with the pixel approach of training and testing data split, the accuracy is acceptable and it matches with the OOB error estimates. To reflect, I think that I haven’t really considered the standards of high urban areas, as Antwerp is in general a lowland plain, the height above sea level is between 2m in the west to 30m in the north. I could have not included high urban areas in my category, however I think adding it could provide more category to create a higher variation in the map."
  },
  {
    "objectID": "Week6.html#application",
    "href": "Week6.html#application",
    "title": "6  Week 6",
    "section": "6.2 Application",
    "text": "6.2 Application\nMachine learning offers a lot to remote sensing by providing effective and efficient classification of imagery, hence, a lot of studies have applied machine learning into their methodology for image classification.\n\n6.2.1 Utilising classified image\n\n6.2.1.1 Urban Expansion\nUrban land use chages have long been a hot topic for the research field, the incoporation of satellite images and GIS has generated a new dimension for researchers to assess and monitor land use cover change (Tewolde and Cabral 2011). But the raw images captured from remote sensors are not easy to use as they do not convey any useful information for analysis, hence, studies that use satellite images for urban land use changes area often classified, creating a scale of values to compare and use.\nFor instance, in a study on Eritrea, an independent state in north-eastern Africa, its capital city Asmara was examined with its settlement patterns of urban and suburban areas. Images used were Landsat TM satellite images with 30m resolution from 1908, 2000 and 2009. Processing steps of landsat image is shown below:\n\n\n\n\n\nData and Methodology used for image classification and result validation. Source: https://www.mdpi.com/2072-4292/3/10/2148\n\n\n\n\nObject-Based Image Analysis (OBIA) was adopted to classify images at image object level instead of pixel level. For land use study, OBIA is useful because the real world is not made up of pixels, instead, it is arrnaged in objects. Therefore, OBIA can avoid mixed pixel problems such as bare sand soil and the impervious parts of urban areas could create a mixed pixel problem. Hence, with classified images, it can be put to a model for analysis in urban expansion.\n\n\n6.2.1.2 Air Pollution and LULC\nClassified images are useful for identifying air pollution and monitoring variations. For instance, images with classified land use and land cover (LULC) can combine with air quality data, such as the type of air pollutiants, concentration of pollutant particles to see where in the image of an area is prone to air pollution. To illustrate, a study by (Superczynski and Christopher 2011) has explored LULC and Pm2.5 emissions. The classified images to LULC map was linked to Pm2.5 mass concentration in Alabama to examine the correlation between the two variables. Classification was done with selecting representative samples for each class, which is a supervised classification. It was mentioned that some calssed in the image has to be split into subclasses and combined into Level I Anderson classification in post-classification processing. The figure below shows the result of classification to urban areas in Birmingham in Alabama. Then, the data was used to compute with Pm2.5 data for further air pollution analysis.\n\n\n\n\n\nprogression of urbanized land around the city of Birmingham since 1998. Source: https://www.mdpi.com/2072-4292/3/12/2552\n\n\n\n\nI think remote sensing produces images that sometimes cannot be used directly to reflect a phenomenon or issue as they only capture what is present on earth and the objects that are always existing for the sensors. However, I think using the images to generate indirect output and reflect to other issues is very smart, for example the land use and land cover map linking back to Pm2.5 is quite impressive as it shows not only the Pm2.5 concentration, but also how land use vary or contribute to Pm2.5."
  },
  {
    "objectID": "Week6.html#reflection",
    "href": "Week6.html#reflection",
    "title": "6  Week 6",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nThis lecture certainly covers a lot of content, which I haven’t been able to capture all in my diary, but it makes me having deeper impression on image classification. Classification of image in remote sensing is much more complicated than I think. I originally think image classification is just a simple process by identifying different colour in the image, but in fact, it involves a lot of different technical and mathematical parameters that could generate different results. It is quite interesting that machine learning is actually very commonly used for image classification. I really like the idea of random forest in machine learning as it adopts the “wisdom of the crowds” approach, to achieve higher accuracies. Especially the random forest can avoid problems like overfitting by using many more trees. The only big drawback for random forest is that it requires high computationand is relatively more time consuming. In general, just the thought of many decision trees stacking up to a whole forest for machine learning is fascinating , complex and mysterious to me, because it would require very long time to understand which path has a value gone through to be generated. I think this lecture covers\n\n\n\n\nSuperczynski, Stephen D., and Sundar A. Christopher. 2011. “Exploring Land Use and Land Cover Effects on Air Quality in Central Alabama Using GIS and Remote Sensing.” Remote Sensing 3 (12): 2552–67. https://doi.org/10.3390/rs3122552.\n\n\nTewolde, Mussie G., and Pedro Cabral. 2011. “Urban Sprawl Analysis and Modeling in Asmara, Eritrea.” Remote Sensing 3 (10): 2148–65. https://doi.org/10.3390/rs3102148."
  },
  {
    "objectID": "Week7.html#summary-of-lecture-7",
    "href": "Week7.html#summary-of-lecture-7",
    "title": "7  Week 7",
    "section": "7.1 Summary of Lecture 7",
    "text": "7.1 Summary of Lecture 7\n\n\n\n\n\nThe feature relations map learning (FRML) chart for hyperspectral image classification. Source: mdpi.com/2072-4292/12/18/2956\n\n\n\n\nDue to the synoptic view nature in remote sensing images, the remote sensing images produces are in map-like format, making it a viable source of gathering effective land cover information. However, just the raw image and identification with the naked eye is not reliable and accurate. Therefore, basic image classification is important to categorize all pixels in a digital image into one of several classes. Image classification is regarded as one of the most essential part in digital image analysis as it allows allocation of semantic labels to capture image. It is useful for research, and policy making purposes as it provides better understanding and details to the content within the image. The image above is a type of image processing using a technique of Feature Relations Map Learning for hyperspectral image, it automatically enhance the separability of different objects in an image (Dou and Zeng 2020). While using a segmented feature relations map (SFRM), it reflects the relations between spectral features through a normalized difference index (NDI), and it can then learn new features from SFRM using a CNN-based feature extractor (Dou and Zeng 2020). Conventionally, there are three types of image classification, including\n\nManual Classification\nPixel-based classification\n\nSupervised image classification\nUnsupervised image classification\n\nFeature or object-based image classification\n\n\n7.1.1 Pixel-based Classification\nIn pixel-based classification, there are two types of image classifications,including Unsupervised and Supervised classification, where unsupervised classification is calculated by the software supervised is mainly a human-guided classification. The supervised image classification creates outcomes that are based on the software analysis without giving it sample classes. On the other hand, unsupervised classification creates outcome that is aided by providing sample pixels in an image that are representative of specific classes and then direct the image processing software to use these training sites as references for the classification of all other pixels in the image. The figures below shows the two types of image classification technique used on the same image, producing approximately similar results, yet the details are quite different.\n\n\n\n\n\nSupervised and unsupervised classification on an image. Source: https://beekangsi.com/the-pros-and-cons-supervised-and-unsupervised-image-classification/\n\n\n\n\nReferencing to (BEKAN 2022)’s GIS blog about the pros and cons of supervised and unsupervised image classification, both classification techniques have their advantages and disadvantages, it is hard to determine which technique is better as it depends on the focus with the results. The\n\n\n\n\n\n\n\n\n\nAdvantage\nDisadvantage\n\n\n\n\nUnsupervised Classification\n\nThe operator can spot mistakes and often corrects them.\nThe analyst does not have to worry about matching categories on the final map to field data.\nThe process is completely within the control of the analyzer.\nSpecific sections of known identity are linked to processing.\nthe class s defined by the Analyst\n\n\n\n\ngathering training for different class is very difficult and time consuming\nthe unrepresented place in training data is difficult to recognize\nneeds very clear training process\nand also requires labelled data set\n\n\n\nSupervised Classification\n\nIt is not necessary to label the training data set.\nit is time saving process\nfast classification\n\n\nAlong the classification process, there is no concept of output.\nIt is not possible to estimate or map the outcome of a new sample.\nIn the presence of outliers, the outcome varies greatly.\n\n\n\n\n\n\n7.1.2 Object Based Image Analysis (OBIA)\nIn the lecture, another type of image classification is taught, the Object based image analysis (OBIA). It involves pixels first being grouped into objects based on either spectral similarity or an external variable such as ownership, land use, shape and geological unit. Superpixels in OBIA are segmentating an image into regions by considering similarity(homogenity) or difference(heterogeneity) measures defined using perceptual features. To achieve that, Simple Linear Iterative Clustering (SLIC) algorithm is commonly used to generate Superpixels. SLIC uses euclidean distance to work out spatial distance between points to centre of pixels and is an adapted k means clustering. Thereby, it does not consider connectivity and do not compare each pixels with all pixels in the scene. Different from SLIC, another version of SLIC that is parameter-free has been proposed, called SLICO. It generates regular shaped Superpixels across the scene, regardless of textured or non-textured regions in the image.\n\n\n\n\n\nSLIC and SLICO Superpixel Generation. Source: https://www.mdpi.com/2072-4292/9/3/243\n\n\n\n\n\n\n7.1.3 Sub-Pixel Analysis\nSub pixel classification (SPC) extracts meaningful information on land-cover classes from the mixed pixels. The figure below shows what a mixed pixel looks like. The proportion and abundance of each classes in the mixed pixel can be accounted for. In general, a few endmembers that are specturally pure are generated will work out fractions per pixel and establish a spectral library.\n\n\n\n\n\nSparse modeling at sub-pixel level using the pre-learned dictionary. Source: https://www.mdpi.com/2072-4292/13/2/190\n\n\n\n\nAccording to (Powell et al. 2007), for multiple endmember, Spectral mixture analysis (SMA) is done based on the assumptionthat the reflectance P’ measured at pixel i can be modeled as the linear sum of N endmembers, or spectrally ‘pure’ materials, weighted by the fraction cover fki of each endmember within the field of view of pixel i. Below shows the calculation of the sum of end member reflectance franction contribution to best-fit mixed spectrum where eiλ is a residual term indicating the disagreement between the measured and modeled spectra.:\n\\[\np_i\\lambda=\\sum_{k=1}^{n} (p_{ki\\lambda} * f_ki) + ei_\\lambda\n\\]\nBy the end, there will be the percentage/fraction of components for each pixels, for example, fraction of vegetation, soil, urban areas.\n\n\n7.1.4 GEE practice with Shiga\nTo actually understand how classification works, in this week’s practical, I have chosen Shiga, a prefecture of Japan that is located in the Kansai Region of Honshu. I have used Landsat data and vector data of area boundary. As the location has a very big lake, I thought it would show clear result for at least water and land, therefore I chose this as my area of study.\n\n\n\n\n\nShiga\n\n\n\n\n\n7.1.4.1 Sup-pixel analysis in Shiga\nTo perform sub-pixel analysis, I have defined variables as endmembers, then using unmix() function in GEE to add up the data and generate image. Similar to previous practicals, I have to filter the data with lower cloud coverage and within a time frame. But for the limited data available in the area, I adjusted the date from 2019-01-01 to 2023-3-10. After masking the cloud cover, the image is clipped to the boundary.\n\n\n\n\n\nShiga\n\n\n\n\nInstead of inserting the coordinate values for the endmembers, I used the geometry function to generate a list of values for each category and extract the mean. As I have 6 categories, I did not want to redo everything manually, therefore I followed the practical to make the process of extracting mean value to a function and applied to the other landcover data. Finally, using unmix() on the processed data to create a map. However, as the map shown is unconstrained, the don’t sum up to 1, hence another function of ee.Image.unmix() is used to compute the pseudo-inverse and multiplying through each pixel, then the image will return with positive values.\n\n\n\n\n\nSub-pixel and fixing th unconstrained problem\n\n\n\n\nThe main concern with the result above is the generation of error matric, hence there will be the part of hardening the sub-pixel image and classify each pixel that has the largest proportion of land cover. A chunk of code that manually assign value to each category of data with a threshold is done, for example, pixels that are greater than 0.5 will be assigned as 1 and if it is 0.5or below, it will be assigned as 0. After all the computation to reclassify each class, the different class of data needs to be added together. And the result is:\n\n\n\n\n\nReclassified sub-pixel result\n\n\n\n\nJust from the figure above, I can’t interpret or explain if the analysis is accurate or not, I am not sure ifin GEE, there are some functions to view or reveal the statistics of the analysis. But I think for now I can’t think of a way to interpret the results, such as explaining the accuracy, error etc.\n\n\n7.1.4.2 Object based image analysis (OBIA)\nFrom the previous summary about OBIA, it involves pixels first being grouped into objects based on either spectral similarity. In other words, pixels are grouped together based on some set of rules. To achieve that in the practical, the Image gradient is created from a function of .gradient() to change the intensity and colour in the image. Then, to make it useful for further steps of the analysis, the image gradient has to change to spectral gradient such that it is valuable to the analysis. It is done by .spectralGradient().\n\n\n\n\n\nSpectral Gradient in Shiga\n\n\n\n\nThen, the next obstacle to carry out OBIA is that the pixels are too small and fragmented, there is a need to reduce pixels to fewer objects, hence the k-means clustering is used to reduce pixels.\n\n\n\n\n\nkmeans clustering\n\n\n\n\nAnother option to reduce pixels and create super pixel is the Simple non-iterative clustering (SNIC) by making a seed grid that specifies the spacing in pixels and set a square or a hex grid.\n\n\n\n\n\nReclassified sub-pixel result\n\n\n\n\nAfter that, the clusters will allow some useful information to be extracted, such as NDVI…\n\n\n\n\n\nReclassified sub-pixel result\n\n\n\n\nHowever, when I try to apply classification to the data, it did not work due to a layer that I could not get rid of, it said”(7 bands for 1685346 pixels = 90.0 MiB > 80.0 MiB). If this is a reduction, try specifying a larger ‘tileScale’ parameter.”I have tried to make some of the maps as a note with “//” to make my code less heavy, but it didn’t work. I have also tried to set higher tileScale, it also does not work. I tried to find solutions online but the answers on stack overflow don’t seem to match my problem. Perhaps the region that I use is still too big, hence the computing is overloaded. It’s a shame that I could not report results here, but at the same time I would love to find a solution to resolve this problem someday.\n\n\n\n\n\nLayer Error for classification output"
  },
  {
    "objectID": "Week7.html#application",
    "href": "Week7.html#application",
    "title": "7  Week 7",
    "section": "7.2 Application",
    "text": "7.2 Application\nThe methods mentioned in this lecture are quite advanced and pertinent to reality such as OBIA considers objects instead of pixels. I find this interesting at first because OBIA images look like pixelate images. But after learning about the principle of OBIA, I think it is an effective tool for detecting challenging objects such as animals that can move. In a study by Chabot, Dillon, and Francis (2018), the study aims to detect and count birds in large volumes of aerial imagery using OBIA software. their approach was to select training inmages and manually identify birds first, then establishing image segmentation parameters, including features boundaries, segmentation. They transform the input image into contrast gradient map, where higher values are assigned to pixels along the boundaries of spectrally contrasting features such as Snow geese against a darker ground. After the pre-processing, they compile attribute data of segmented bird objects and set up bird object classification rule sets\n\n\n\n\n\nautomated object-based analysis of large volumes of aerial imagery to detect Lesser Snow Geese. Source: https://www.ace-eco.org/vol13/iss1/art15/#Compiling\n\n\n\n\nI think this study design is very comprehensive and almost flawless as it accounts for most of the potential errors and how to mitigate them. Also, the description and selection of the raw image used is well accounted for. The steps to set up parameters for bird identification and procedure for OBIA are very detailed. I think the project is very interesting because birds are moving objects that are constantly moving. Hence, I wonder if there will be overlapped count for the same bird because it is not possible to identify each individual birds in a remotely sensed image."
  },
  {
    "objectID": "Week7.html#reflection",
    "href": "Week7.html#reflection",
    "title": "7  Week 7",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\nIn this week, I have learnt quite in-depth about image classification in remote sensing. I think different analysis has its own advantage, for example, the sub-pixel analysis takes into account the possibility of a pixel to belong to different classes in an image segmentation context.The mixed pixels makes image classification very precise and high resolution. this has enhanced the quality of output in remote sensing and also helps to broaden the capability of remote sensing in research that require higher resolution images, such as animal studies, deep learning etc.\nAlso with the GEE, I think the OBIA is quite easy to compute as it is only a few lines of codes from reducing pixels through kmeans or create hex or square grids to running a cluster function. In the future, I think I would need more experience with running machine learning model in GEE because the training and testing data split is still complicated for me. Thus, the classification part has been quite confusing to me on how it is actually executed.\n\n\n\n\nBEKAN. 2022. “The Pros and Cons Supervised and Unsupervised Image Classification.” https://beekangsi.com/the-pros-and-cons-supervised-and-unsupervised-image-classification/.\n\n\nChabot, Dominique, Christopher Dillon, and Charles Francis. 2018. “An Approach for Using Off-the-Shelf Object-Based Image Analysis Software to Detect and Count Birds in Large Volumes of Aerial Imagery.” Avian Conservation and Ecology 13 (1). https://doi.org/10.5751/ACE-01205-130115.\n\n\nDou, Peng, and Chao Zeng. 2020. “Hyperspectral Image Classification Using Feature Relations Map Learning.” Remote Sensing 12 (18): 2956. https://doi.org/10.3390/rs12182956.\n\n\nPowell, R, D Roberts, P Dennison, and L Hess. 2007. “Sub-Pixel Mapping of Urban Land Cover Using Multiple Endmember Spectral Mixture Analysis: Manaus, Brazil.” Remote Sensing of Environment 106 (2): 253–67. https://doi.org/10.1016/j.rse.2006.09.005."
  },
  {
    "objectID": "Week8.html#summary-of-lecture-8",
    "href": "Week8.html#summary-of-lecture-8",
    "title": "8  Week 8",
    "section": "8.1 Summary of Lecture 8",
    "text": "8.1 Summary of Lecture 8\nThis week, we covered Urban Heat Island (UHI) and policy related to it. UHI effects occur when cities replace natural land cover with dense concentrations of pavement, buildings and urban structures that absorb and retain heat. In highly concentrated urban areas with limited greenery, the area will become “islands” of higher temperatures relative to outlying areas (US EPA 2014). There are factors that cause and intensify UHI, such as heat generated from human activities, weather and geography and reduced natural landscapes in urban areas. However, from the view of remote sensing, there are two main factors that is identified as UHI from the images, including the dark surfaces that retain heat and less vegetation to regulate temperature. Other than that, another factor would be the low Sky View Factor(SVF),how much we can see the sky when we look up. The magnitude of UHI in world cities are shown below, showing the variations in different regions.\n\n\n\n\n\nMap of summertime UHI intensity in world cities (a), EU (b), and SEA (c). d–g, Observed probability distribution of ΔTs (d), population N (e), mean annual precipitation P (f), and urban green cover gc,u (g). Large circles in b, c indicate cities with green cover data20,22 used to compute the statistics in d–. Source:https://www.nature.com/articles/s41586-019-1512-9\n\n\n\n\nUnfortunately, UHI actual costs economic loss. Economist expected that climate change can cost a lot of money and impact every sector of the economy. It was expected that if UHI is intensifies, there will be higher cost for the city, which will be caused by the replacement of vegetation and bodies of water by concrete, asphalt, and other materials that trap more heat (“Urban Heat Island Effect Could More Than Double Climate Costs for Cities” 2017). Socially, for Shanghai, it was expected that people from urban area would have much higher excess mortality rate due to hot related illness than those from exurban areas. Since this is not a local issue, but globally occurring in different metropolis, urban areas, hence some international regulations should be discussed below.\n\n8.1.1 Global policy\nFrom the perspective of the whole world, the urban population around the world has doubled from 1754 million in 1980 to 3,594 million in 2010, and this number will reach up to 5,167 million in 2030 (United Nations, 2018). It was predicted that by 2050, over 68% of the global population will be living in cities, the rapid urbanisation has caused the various problems, especially when urban areas actually only constitute less than 1% of the earth’s surface. UHI has become a more concerning issue across the globe. In 2021, the UN Environment Programme (UNEP) published detailed guidance to help the world combatting extreme heat, especially in urban areas where heating occurs twice the global average rate. THe book is caled Beating the Heat: A Sustainable Cooling Handbook for Cities. The handbook notes that the demand for space cooling increasing and the fact that urban heat is not evenly distributed. I think that the handbook has a lot of pages, which might be lengthy to most of the people. However, when it comes to city planning, I believe that city planner are going to find this handbook handy as it provides comprehensive overview of tools to cool cities sustainably and equitably. Also, with 80 supporting case studies that are currently running in the world, I think it would be useful for city planners to reference and create a more sustainable plan for cooling cities accordingly.\nBelow shows some of the case studies\n\n\n\n\n\n\n\n\nCity\nMeasures\nGoals\n\n\n\n\nSeoul, South Korea\nRestore the Cheonggyecheon stream that runs through the city replaced 5.8 kilometres of elevated expressway covering the stream with a mixed-use waterfront corridor.\nThe waterfront corridor decreased temperature 3.3°C to 5.9°C compared to a parallel road a few blocks away\n\n\nMedellín, Colombia\nFrom 2016 to 2019, the city created 36 corridors, 18 along major roads and 18 along waterways, covering over 36 hectares.\nThe areas with green corridors have already seen temperature reductions of up to 4°C\n\n\nGuangzhou, China\nThe municipal government adopted regional centralized cooling as part of a green and environmentally friendly modern urban centre in the core area of the Pearl River New City development\nThe local environmental temperature in the core area of Zhujiang New Town was reduced by 2-3°C compared to using distributed cooling systems.\n\n\n\nIn remote sensing, it is capable to provide global and temporal observations to monitor the effects brought by UHI. One common way to capture data about UHI is through thermal mapping to monitor the Land Surface Temperature (LST). Other than UHI, Voogt and Oke (2003) suggested an alternative sub-classification analogous to UHI, called Surface Urban Heat Island (SUHI). The SUHI studies surface temperature differences between urban and rural areas, also addresses temporal variability.\n\n\n8.1.2 Hong Kong’s UHI\nIn this practical, I have chosen my hometown Hong Kong to analysis the UHI with Landsat and MODIS. The reason I chose Hong Kong is because it is high density city situated in the sub-tropical climate region with hot and humid summer months. Hence, it is a city that suffers from UHI and is valuable to examine. I load up a level 2 administrative area to extract temperature data for Hong Kong in summer months from May to September. As mentioned in the practical, the data comes with Kelvin (K), converting it back to celcius (C), the formula is\nC = K - 273.15.\nHence, with the ImageCollection extracted from “2018-01-01’, ’2022-12-10” in May to September, there are many images used. I have to put larger range in the date as the data is not sufficient with only 2 year, it did not cover the administrative area of Hong Kong. the .subtract doesn’t work on ImageCollection, so the 273.15 from the formula is adopted to subtract each image within the collection. After that, the reducer using mean as argument is used to create a map.\n\n\n\n\n\nHong Kong’s Landsat image\n\n\n\n\nThe same process is done with adopting another instrument called Moderate Resolution Imaging Spectroradiometer (MODIS). It is an instrument that aboard both Terra and Aqua satellites. The scale factor has to be applied because the resolution for MODIS data is at 1km resolution. Therefore, I used the scale factor to multiply by 0.02 and subtract with 273.1 (for the kelvin celcius change). In addition, I have adjusted the range of date from January to Octorber as the results are not very effective if I only include May to September.\n\n\n\n\n\nHong Kong’ MODIS Land Surface Temperature\n\n\n\n\nThe time series for MODIS data from May to September is shown below. The range of temperature is not large, the average temperature is above 25 degrees, with only slight fluctuation. However, it can be seem that some days are above 35 degrees.\n\n\n\n\n\nHong Kong’ MODIS Land Surface Temperature"
  },
  {
    "objectID": "Week8.html#application",
    "href": "Week8.html#application",
    "title": "8  Week 8",
    "section": "8.2 Application",
    "text": "8.2 Application\nIn the summary, I have covered the global policy on UHI, for application, I will use a local policy as an example on how cities have been adopting to combat and mitigate UHI.\n\n8.2.1 Local Policy\n\n8.2.1.1 New Orleans, US\nIn the US, Climate Central, nonprofit news organization, created an index to evaluate the intensity of urban heat islands and applied it to 159 cities across the U.S by measuring the type of land cover in each city, from greenspace to paved areas, and factoring in building height and population density. The cities with the five most intense urban heat islands are New Orleans, Newark, N.J., New York City, Houston, and San Francisco. According to a study by the Climate Central, on average the city is about 9 degrees hotter than the surrounding countryside.\nThe figure below illustrates the average surface temperatures in New Orleans from 2019 to 2021. The areas with higher temperature are areas with less than 10% of tree canopy. Hence, the authority has decided to implement plans to combat the rising surface temperature in urban areas.\n\n\n\n\n\nSurface temperatures in New Orleans (2019-2021) Source:Spackman Mossop Michaels\n\n\n\n\nTo combat extreme heat, authority in New Orleans proposed a new master plan for rebuilding its urban forest calls for 100,000 new trees to be planted by 2040. It was hoping that the strategic planting of 100,000 trees could increase the tree canopy in each New Orleans neighborhood to cover at least 10% of the area. While trees and plants have a significant cooling benefit, the reforestation plan offers a more equitable model to reduce dangerous extreme heat while lowering energy use.\n\n\n\n\n\nA mix of imagery and LiDAR paint a picture New Orleans’ tree canop Soruce:https://www.wwno.org/coastal-desk/2023-01-20/new-orleans-has-a-new-goal-for-building-a-greener-city-plant-100k-trees-in-20-years\n\n\n\n\nI personally think that this approach is very pragmatic and reasonable, as trees area essentially the most effective and immediate effect to cool heat. In fact, most of the countries wen combating heat, they try to build trees to cool down the city. However, I am concerned about the maintenance and growth of the newlyplanted trees, just like what Madrid did with the metropolitan forest in week 4, the maintenance of the growth of trees are very important because it without proper management, trees might overgrown, the roots might damage structure etc. Hence, I think planting trees are a good method to combat UHI effects, but there is a need to properly manage afterwards, especially in an area that is already densely populated and dense with development."
  },
  {
    "objectID": "Week8.html#reflection",
    "href": "Week8.html#reflection",
    "title": "8  Week 8",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\nI think urban heat island is a topic that has be brought up for years, and I always felt the effects of UHI as Hong Kong is always really hot, not only because it is located within the suptropical climate, but definitely the high rise buildings, and the materials in densely populated urban areas have an effect on retaining and absorbing heat. One interesting fact is that Hong Kong rely on air conditioning heavily during summer time. Not only do shopping malls or public areas use air conditioning, even people at home turn on the air conditioner for full day because it is too hot. However, this actually creates a vicious cycle on UHI effects because it uses large amount of energy and produce more heat when it is turned on. to look broader, Greenhouse Gas (GHGs) and burning of fossil fuels to provide electricity for air conditioning might exercebate global warming.Hence, I think that not only from building things of the existing things to cool down surface, policies should also address issues like the excessive use of electricity on cooling, which actually contributes back to UHI.\n\n\n\n\n“Urban Heat Island Effect Could More Than Double Climate Costs for Cities.” 2017. https://news.mongabay.com/2017/06/urban-heat-island-effect-could-more-than-double-climate-costs-for-cities/.\n\n\nUS EPA, OAR. 2014. “Learn About Heat Islands.” https://www.epa.gov/heatislands/learn-about-heat-islands."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "9  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Aplin, Paul. 2004. “Remote Sensing: Land Cover.”\nProgress in Physical Geography: Earth and Environment 28 (2):\n283–93. https://doi.org/10.1191/0309133304pp413pr.\n\n\nTempfli, Klaus, G. C. Huurneman, Wim Bakker, L. L. F. Janssen, W. F.\nFeringa, Ambro Gieske, K. A. Grabmaier, et al. 2009. “Principles\nof Remote Sensing : An Introductory Textbook.” In, 56–85."
  },
  {
    "objectID": "Week2.html#xaringan-slide-presentation-on-synthetic-aperture-radar-sar",
    "href": "Week2.html#xaringan-slide-presentation-on-synthetic-aperture-radar-sar",
    "title": "2  Week 2",
    "section": "3.3 Xaringan slide presentation on Synthetic Aperture Radar (SAR)",
    "text": "3.3 Xaringan slide presentation on Synthetic Aperture Radar (SAR)\nThis week, the weekly task is to create a xaringan preentation on a sensor, and I have chosen Synthetic Aperture Radar (SAR)."
  },
  {
    "objectID": "Week2.html#week-2",
    "href": "Week2.html#week-2",
    "title": "2  Week 2",
    "section": "2.1 Week 2",
    "text": "2.1 Week 2\nIn week 2, we have learnt concepts of Xanringan and Quarto.\n\n2.1.1 Xaringan\n[ʃaː.’ riŋ.ɡan] is an R package for creating slideshows with remark. js through R Markdown.\n\n\n\n\n\nXaringan Logo\n\n\n\n\nIt uses JavaScript library remark.js (https://remarkjs.com) to generate HTML5 presentations of a different style. According to the author of Xaringan, he claims that the name “xaringan” came from Sharingan (http://naruto.wikia.com/wiki/Sharingan) in the Japanese manga and anime “Naruto”. It was meant to be a difficult word to understand and pronounce as the author did not want this style of slideshow to be too popular.\n\n\n2.1.2 Quarto\nan open-source scientific and technical publishing system built on Pandoc. It allows you to publish Python, R, Julia or Observable in a online book or presentation. It combines the functionality of R Markdown, bookdown, distill, and other packages into a single system.\n\n\n\n\n\nQuarto logo. Source:https://www.jumpingrivers.com/blog/quarto-rmarkdown-comparison/\n\n\n\n\n\n\n2.1.3 Xaringan slide presentation on Synthetic Aperture Radar (SAR)\nThis week, the weekly task is to create a xaringan preentation on a sensor, and I have chosen Synthetic Aperture Radar (SAR)."
  },
  {
    "objectID": "Week8.html#local-policy",
    "href": "Week8.html#local-policy",
    "title": "8  Week 8",
    "section": "8.2 Local Policy",
    "text": "8.2 Local Policy\n\n8.2.1 New Orleans, US\nIn the US, Climate Central, nonprofit news organization, created an index to evaluate the intensity of urban heat islands and applied it to 159 cities across the U.S by measuring the type of land cover in each city, from greenspace to paved areas, and factoring in building height and population density. The cities with the five most intense urban heat islands are New Orleans, Newark, N.J., New York City, Houston, and San Francisco. According to a study by the Climate Central, on average the city is about 9 degrees hotter than the surrounding countryside.\nThe figure below illustrates the average surface temperatures in New Orleans from 2019 to 2021. The areas with higher temperature are areas with less than 10% of tree canopy. Hence, the authority has decided to\n\n\n\n\n\nSurface temperatures in New Orleans (2019-2021) Source:Spackman Mossop Michaels\n\n\n\n\nTo combat extreme heat, authority in New Orleans proposed a new master plan for rebuilding itsurban forest calls for 100,000 new trees to be planted by 2040. It was hoping that the strategic planting of 100,000 trees could increase the tree canopy in each New Orleans neighborhood to cover at least 10% of the area. While trees and plants have a significant cooling benefit, the reforestation plan offers a more equitable model to reduce dangerous extreme heat while lowering energy use.\n\n\n\n\n\nA mix of imagery and LiDAR paint a picture New Orleans’ tree canop Soruce:https://www.wwno.org/coastal-desk/2023-01-20/new-orleans-has-a-new-goal-for-building-a-greener-city-plant-100k-trees-in-20-years"
  },
  {
    "objectID": "Week8.html#global-policy",
    "href": "Week8.html#global-policy",
    "title": "8  Week 8",
    "section": "8.3 global policy",
    "text": "8.3 global policy\nFrom the perspective of the whole world, the urban population around the world has doubled from 1754 million in 1980 to 3,594 million in 2010, and this number will reach up to 5,167 million in 2030 (United Nations, 2018). It was predicted that by 2050, over 68% of the global population will be living in cities, the rapid urbanisation has caused the various problems, especially when urban areas actually only constitute less than 1% of the earth’s surface. UHI has become a more concerning issue across the globe. In 2021, the UN Environment Programme (UNEP) published detailed guidance to help the world combatting extreme heat, especially in urban areas where heating occurs twice the global average rate. THe book is caled Beating the Heat: A Sustainable Cooling Handbook for Cities. The handbook notes that the demand for space cooling increasing and the fact that urban heat is not evenly distributed. I think that the handbook has a lot of pages, which might be lengthy to most of the people. However, when it comes to city planning, I believe that city planner are going to find this handbook handy as it provides comprehensive overview of tools to cool cities sustainably and equitably. Also, with 80 supporting case studies that are currently running in the world, I think it would be useful for city planners to reference and create a more sustainable plan for cooling cities accordingly.\nBelow shows some of the case studies\n\n\n\n\n\n\n\n\nCity\nMeasures\nGoals\n\n\n\n\nSeoul, South Korea\nRestore the Cheonggyecheon stream that runs through the city replaced 5.8 kilometres of elevated expressway covering the stream with a mixed-use waterfront corridor.\nThe waterfront corridor decreased temperature 3.3°C to 5.9°C compared to a parallel road a few blocks away\n\n\nMedellín, Colombia\nFrom 2016 to 2019, the city created 36 corridors, 18 along major roads and 18 along waterways, covering over 36 hectares.\nThe areas with green corridors have already seen temperature reductions of up to 4°C\n\n\nGuangzhou, China\nThe municipal government adopted regional centralized cooling as part of a green and environmentally friendly modern urban centre in the core area of the Pearl River New City development\nThe local environmental temperature in the core area of Zhujiang New Town was reduced by 2-3°C compared to using distributed cooling systems.\n\n\n\nIn remote sensing, it is capable to provide global and temporal observations to monitor the effects brought by UHI. One common way to capture data about UHI is through thermal mapping to monitor the Land Surface Temperature (LST). Other than UHI, Voogt and Oke (2003) suggested an alternative sub-classification analogous to UHI, called Surface Urban Heat Island (SUHI). The SUHI studies surface temperature differences between urban and rural areas, also addresses temporal variability. In this practical, I have chosen my hometown Hong Kong to analysis the UHI with Landsat and MODIS. The reason I chose Hong Kong is because it is high density city situated in the sub-tropical climate region with hot and humid summer months. Hence, it is a city that suffers from UHI and is valuable to examine."
  },
  {
    "objectID": "Week6.html#section",
    "href": "Week6.html#section",
    "title": "6  Week 6",
    "section": "6.3 ",
    "text": "6.3"
  }
]